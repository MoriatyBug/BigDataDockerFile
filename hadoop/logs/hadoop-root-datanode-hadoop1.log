2020-03-27 22:09:46,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-27 22:09:46,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-27 22:09:47,246 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-27 22:09:47,483 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-27 22:09:47,538 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-27 22:09:47,538 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-27 22:09:47,542 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-27 22:09:47,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-27 22:09:47,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-27 22:09:47,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-27 22:09:47,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-27 22:09:47,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-27 22:09:47,649 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-27 22:09:47,658 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-27 22:09:47,663 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-27 22:09:47,667 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-27 22:09:47,670 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-27 22:09:47,670 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-27 22:09:47,670 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-27 22:09:47,680 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40125
2020-03-27 22:09:47,680 INFO org.mortbay.log: jetty-6.1.26
2020-03-27 22:09:47,839 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40125
2020-03-27 22:09:47,953 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-27 22:09:48,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-27 22:09:48,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-27 22:09:58,116 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-27 22:09:58,128 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-27 22:09:58,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-27 22:09:58,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-27 22:09:58,181 WARN org.apache.hadoop.hdfs.DFSUtil: Namenode for ns1 remains unresolved for ID nn1.  Check your hdfs-site.xml file to ensure namenodes are configured properly.
2020-03-27 22:09:58,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-27 22:09:58,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2:9000 starting to offer service
2020-03-27 22:09:58,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.2:9000 starting to offer service
2020-03-27 22:09:58,196 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-27 22:09:58,196 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-27 22:09:58,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:09:59,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:00,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:01,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:02,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:03,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:03,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:04,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:05,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:06,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:07,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:08,263 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:08,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:08,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-03-27 22:10:13,263 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:14,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:15,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:16,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:17,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:18,263 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:18,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:19,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:20,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:21,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:22,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:23,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:23,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:23,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-03-27 22:10:28,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:29,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:30,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:31,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:32,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:33,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:33,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:34,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:35,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:36,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:37,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:38,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:38,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:38,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-03-27 22:10:43,266 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:44,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:45,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:46,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:10:48,266 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:53,267 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:10:56,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 225@hadoop1
2020-03-27 22:10:56,265 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1961412683-172.17.0.32-1450036414523
2020-03-27 22:10:56,265 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1961412683-172.17.0.32-1450036414523
2020-03-27 22:10:56,266 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-03-27 22:10:56,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1995885711;bpid=BP-1961412683-172.17.0.32-1450036414523;lv=-56;nsInfo=lv=-63;cid=CID-5e691286-4de5-4dde-800b-c02a7a8bf44a;nsid=1995885711;c=0;bpid=BP-1961412683-172.17.0.32-1450036414523;dnuuid=5c2745ab-8b04-406c-a9d7-c513e9d8983b
2020-03-27 22:10:56,361 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ef9a5443-f667-4e9d-8725-f14df066e7d7
2020-03-27 22:10:56,361 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2020-03-27 22:10:56,395 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-03-27 22:10:56,395 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1961412683-172.17.0.32-1450036414523
2020-03-27 22:10:56,396 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data/current...
2020-03-27 22:10:56,442 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1961412683-172.17.0.32-1450036414523 on /tmp/hadoop-root/dfs/data/current: 45ms
2020-03-27 22:10:56,442 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1961412683-172.17.0.32-1450036414523: 46ms
2020-03-27 22:10:56,445 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data/current...
2020-03-27 22:10:56,459 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data/current: 14ms
2020-03-27 22:10:56,459 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 17ms
2020-03-27 22:10:56,764 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now rescanning bpid BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data, after more than 504 hour(s)
2020-03-27 22:10:56,768 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1585362429768 with interval 21600000
2020-03-27 22:10:56,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid null) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:10:56,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid null) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:10:56,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoop1/172.19.0.2:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-03-27 22:10:56,887 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-ef9a5443-f667-4e9d-8725-f14df066e7d7): finished scanning block pool BP-1961412683-172.17.0.32-1450036414523
2020-03-27 22:10:56,891 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-ef9a5443-f667-4e9d-8725-f14df066e7d7): no suitable block pools found to scan.  Waiting 1814399873 ms.
2020-03-27 22:10:56,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:10:56,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:10:56,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:10:56,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:10:56,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:10:56,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:10:56,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:10:56,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:10:56,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:10:56,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3ff21f4874d,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 4 msec to generate and 14 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:10:58,267 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:03,268 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:08,268 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:13,269 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:18,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:23,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:28,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:33,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:38,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:43,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:48,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:53,274 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:11:58,274 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:03,275 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:08,275 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:13,276 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:18,276 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:23,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:28,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:33,278 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:38,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:43,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:48,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:53,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:12:58,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:03,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:08,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:13,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:18,283 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:23,283 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:28,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:33,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:38,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:43,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:48,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:53,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:13:58,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:03,288 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:08,288 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:13,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:18,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:23,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:28,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:33,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:38,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:43,292 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:48,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:53,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:14:58,294 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:03,294 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:08,295 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:13,295 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:18,297 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:23,297 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:28,298 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:33,298 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:38,299 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:43,299 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:48,300 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:53,301 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:15:58,301 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:03,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:08,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:13,303 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:18,303 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:23,304 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:28,304 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:33,305 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:38,305 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:43,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:48,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:53,307 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:16:58,307 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:03,308 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:08,308 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:13,309 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:18,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:23,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:28,311 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:33,311 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:38,312 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:43,312 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:48,313 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:53,313 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:17:58,314 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:03,314 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:08,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:13,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:18,316 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:23,316 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:28,317 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:33,317 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:38,318 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:43,318 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:48,319 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:53,319 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:18:58,320 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:03,320 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:08,321 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:13,322 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:18,322 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:23,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:28,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:33,324 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:38,324 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:43,325 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:48,325 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:53,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:19:58,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:03,327 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:08,327 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:13,328 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:18,328 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:23,329 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:28,329 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:33,330 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:38,331 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:43,331 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:48,332 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:53,332 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:20:58,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:03,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:08,334 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:13,334 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:18,335 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:23,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:28,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:33,337 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:38,337 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:43,338 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:48,338 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:53,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:21:58,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:03,340 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:08,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:13,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:18,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:23,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:28,343 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:33,343 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:38,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:43,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:48,345 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:53,345 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:22:58,346 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:03,346 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:08,347 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:13,347 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:18,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:23,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:28,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:33,349 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:38,350 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:43,350 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:48,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:53,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:23:58,352 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:03,352 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:08,353 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:13,353 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:18,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:23,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:28,355 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:33,355 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:38,356 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:43,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:48,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:53,358 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:24:58,358 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:03,359 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:08,359 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:13,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:18,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:23,361 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:28,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:33,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:38,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:43,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:48,364 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:53,364 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:25:58,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:03,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:08,366 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:13,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:18,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:23,368 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:28,368 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:33,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:38,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:43,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:48,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:53,371 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:26:58,371 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:03,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:08,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:09,800 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1961412683-172.17.0.32-1450036414523 Total blocks: 31, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-03-27 22:27:13,373 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:18,374 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:23,374 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:28,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:33,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:38,376 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:43,376 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:48,377 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:53,377 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:27:58,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:03,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:08,379 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:13,379 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:18,380 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:23,380 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:28,381 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:33,382 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:38,382 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:43,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:48,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:53,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:28:58,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:03,385 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:08,385 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:13,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:18,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:23,387 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:28,387 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:33,388 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:38,388 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:43,389 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:48,389 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:53,390 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:29:58,390 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:03,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:08,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:13,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:18,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:23,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:28,394 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:33,394 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:38,395 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:43,395 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:48,396 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:53,396 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:30:58,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:03,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:08,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:13,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:18,399 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:23,399 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:28,400 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:33,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:38,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:43,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:48,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:53,403 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:31:58,403 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:03,404 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:08,404 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:13,405 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:18,405 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:23,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:28,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:33,407 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:38,408 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:43,408 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:48,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:53,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:32:58,410 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:03,410 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:08,411 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:13,412 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:18,412 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:23,413 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:28,413 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:33,414 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:38,414 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:43,415 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:48,415 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:53,416 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:33:58,416 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:03,417 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:08,418 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:13,418 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:18,419 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:23,419 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:28,420 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:33,420 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:38,421 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:43,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:48,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:53,423 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:34:58,423 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:03,424 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:08,424 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:13,425 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:18,425 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:23,426 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:28,427 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:33,427 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:38,428 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:43,428 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:48,429 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:53,429 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:35:58,430 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:03,431 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:08,431 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:13,432 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:18,432 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:23,433 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:28,433 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:33,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:38,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:43,435 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:48,436 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:53,436 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:36:58,437 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:03,437 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:08,438 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:13,438 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:18,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:23,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:28,440 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:33,441 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:38,441 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:43,442 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:48,442 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:53,443 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:37:58,443 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:03,444 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:08,444 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:13,445 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:18,445 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:23,446 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:28,446 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:33,447 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:38,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:43,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:48,449 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:53,449 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:38:58,450 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:03,450 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:08,451 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:13,451 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:18,452 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:23,453 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:28,453 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:33,454 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:38,454 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:43,455 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:48,455 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:53,456 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:39:58,456 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:03,457 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:08,457 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:13,458 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:18,458 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:23,459 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:28,459 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:33,460 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:38,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:43,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:48,462 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:53,462 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:40:58,463 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:03,463 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:08,464 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:13,464 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:18,465 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:23,466 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:28,466 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:33,467 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:38,467 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:43,468 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:48,468 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:53,469 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:41:58,470 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:03,470 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:08,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:13,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:18,472 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:23,472 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:28,473 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:33,473 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:38,474 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:43,474 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:48,475 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:53,476 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:42:58,476 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:03,477 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:08,477 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:13,478 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:18,478 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:23,479 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:28,479 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:33,480 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:38,481 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:43,481 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:45,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "hadoop1/172.19.0.2"; destination host is: "hadoop1":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2020-03-27 22:43:48,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:48,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:49,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:50,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:51,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:52,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:53,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:53,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:54,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:55,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:56,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:57,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:57,974 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:43:58,483 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:43:58,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:43:59,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:00,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:01,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:02,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:03,483 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:03,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:04,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:05,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:06,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:07,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:07,982 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:44:08,484 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:08,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:09,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:10,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:11,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:12,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:13,484 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:13,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:14,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:15,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:16,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:17,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:17,990 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:44:18,484 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:18,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:19,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:20,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:21,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:22,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:23,485 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:23,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:24,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:25,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:26,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:27,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:28,000 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:44:28,486 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:29,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:30,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:31,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:32,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:33,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:33,486 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:34,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:35,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:36,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:37,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:38,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:38,009 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:44:38,487 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:39,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:40,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:41,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:42,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:43,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:43,487 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:44,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:45,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:46,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:47,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:48,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:48,019 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:44:48,488 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:49,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:50,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:51,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:52,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:53,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:53,488 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:54,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:55,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:56,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:57,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:58,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:44:58,029 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:44:58,489 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:44:59,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:00,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:01,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:02,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:03,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:03,489 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:04,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:05,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:06,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:07,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:08,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:08,039 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:45:08,489 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:09,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:10,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:11,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:12,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:13,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:13,490 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:14,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:15,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:16,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:17,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:18,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:18,047 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:45:18,490 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:19,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:20,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:21,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:22,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:23,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:23,491 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:24,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:25,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:26,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:27,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:28,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:28,056 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:45:28,491 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:29,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:30,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:45:33,492 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:38,497 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:39,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:39,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:39,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:39,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e403c8b124,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 0 msec to generate and 13 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:42,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:42,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:42,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:42,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e4b6ff5d13,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:43,498 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:45,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:45,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:45,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:45,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e56a4caf97,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:48,498 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:48,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:48,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:48,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:48,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e61d94a13c,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:51,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:51,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:51,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:51,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e6d0915eed,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:53,499 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:45:54,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:54,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:54,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:54,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e783e7b2c2,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:57,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.2:9000 with standby state
2020-03-27 22:45:57,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 beginning handshake with NN
2020-03-27 22:45:57,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.2:9000 successfully registered with NN
2020-03-27 22:45:57,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5e83729453c,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-03-27 22:45:58,499 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:00,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "hadoop1/172.19.0.2"; destination host is: "hadoop1":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2020-03-27 22:46:03,500 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:04,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:05,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:06,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:07,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:08,500 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:08,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:09,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:10,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:11,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:12,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:13,501 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:13,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:13,572 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:46:14,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:15,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:16,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:17,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:18,502 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:18,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:19,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:20,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:21,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:22,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:23,502 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:23,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:23,581 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:46:24,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:25,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:26,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:27,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:28,503 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:28,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:29,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:30,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:31,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:32,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:33,503 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:33,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:33,591 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:46:34,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:35,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:36,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:37,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:38,504 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:38,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:39,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:40,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:41,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:42,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:43,504 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:43,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:43,601 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:46:44,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:45,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:46,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:47,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:48,505 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:48,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:49,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:50,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:51,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:52,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:53,506 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:53,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:53,610 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:46:54,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:55,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:56,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:57,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:58,506 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:46:58,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:46:59,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:00,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:01,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:02,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:03,507 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:03,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:03,618 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:47:04,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:05,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:06,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:07,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:08,507 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:08,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:09,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:10,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:11,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:12,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:13,508 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:13,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:13,626 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:47:14,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:15,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:16,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:17,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:18,508 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:18,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:19,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:20,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:21,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:22,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:23,509 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:23,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:23,635 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:47:24,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:25,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:26,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:27,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:28,509 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:28,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:29,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:30,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:31,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:32,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:33,510 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:33,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:33,645 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:47:34,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:35,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:36,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:37,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:38,510 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:38,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:39,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:40,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:41,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:42,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:43,511 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:43,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:43,654 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:47:44,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:45,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:46,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:47,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:48,511 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:48,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:49,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:50,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:51,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:52,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:53,512 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:53,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:53,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:47:54,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:55,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:56,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:57,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:58,512 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:47:58,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:47:59,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:00,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:01,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:02,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:03,513 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:03,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:03,672 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:48:04,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:05,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:06,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:07,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:08,513 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:08,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:09,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:10,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:11,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:12,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:13,514 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:13,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:13,681 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:48:14,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:15,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:16,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:17,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:18,514 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:18,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:19,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:20,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:21,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:22,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:23,515 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:23,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:23,691 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:48:24,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:25,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:26,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:27,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:28,515 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:28,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:29,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:30,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:31,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:32,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:33,516 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:33,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:33,700 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:48:34,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:35,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:36,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:37,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:38,516 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:38,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:39,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:40,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:41,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:42,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:43,517 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:43,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:43,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:48:44,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:45,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:46,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:47,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:48,517 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:48,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:49,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:50,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:51,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:52,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:53,518 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:53,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:53,717 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:48:54,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:55,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:56,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:57,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:58,518 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:48:58,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:48:59,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:00,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:01,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:02,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:03,519 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:49:03,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:03,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From hadoop1/172.19.0.2 to hadoop1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor11.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2020-03-27 22:49:04,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:05,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:06,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:07,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:08,519 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-03-27 22:49:08,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 22:49:09,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-27 23:33:13,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-27 23:33:13,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-27 23:33:14,317 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-27 23:33:14,679 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-27 23:33:14,772 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-27 23:33:14,772 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-27 23:33:14,780 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-27 23:33:14,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-27 23:33:14,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-27 23:33:14,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-27 23:33:14,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-27 23:33:14,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-27 23:33:14,972 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-27 23:33:14,986 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-27 23:33:14,996 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-27 23:33:15,005 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-27 23:33:15,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-27 23:33:15,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-27 23:33:15,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-27 23:33:15,026 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41139
2020-03-27 23:33:15,026 INFO org.mortbay.log: jetty-6.1.26
2020-03-27 23:33:15,279 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41139
2020-03-27 23:33:15,449 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-27 23:33:15,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-27 23:33:15,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-27 23:33:25,689 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-27 23:33:25,736 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-27 23:33:25,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-27 23:33:25,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-27 23:33:25,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-27 23:33:25,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-27 23:33:25,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-27 23:33:25,888 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-27 23:33:25,898 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-27 23:33:34,948 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 307@hadoop1
2020-03-27 23:33:35,214 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1961412683-172.17.0.32-1450036414523
2020-03-27 23:33:35,214 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1961412683-172.17.0.32-1450036414523
2020-03-27 23:33:35,228 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-03-27 23:33:35,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1995885711;bpid=BP-1961412683-172.17.0.32-1450036414523;lv=-56;nsInfo=lv=-63;cid=CID-5e691286-4de5-4dde-800b-c02a7a8bf44a;nsid=1995885711;c=0;bpid=BP-1961412683-172.17.0.32-1450036414523;dnuuid=5c2745ab-8b04-406c-a9d7-c513e9d8983b
2020-03-27 23:33:35,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ef9a5443-f667-4e9d-8725-f14df066e7d7
2020-03-27 23:33:35,306 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2020-03-27 23:33:35,342 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-03-27 23:33:35,343 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1961412683-172.17.0.32-1450036414523
2020-03-27 23:33:35,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data/current...
2020-03-27 23:33:35,423 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1961412683-172.17.0.32-1450036414523 on /tmp/hadoop-root/dfs/data/current: 79ms
2020-03-27 23:33:35,424 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1961412683-172.17.0.32-1450036414523: 81ms
2020-03-27 23:33:35,432 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data/current...
2020-03-27 23:33:35,452 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1961412683-172.17.0.32-1450036414523 on volume /tmp/hadoop-root/dfs/data/current: 20ms
2020-03-27 23:33:35,456 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 32ms
2020-03-27 23:33:35,845 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-ef9a5443-f667-4e9d-8725-f14df066e7d7): no suitable block pools found to scan.  Waiting 1809440919 ms.
2020-03-27 23:33:35,847 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1585383345847 with interval 21600000
2020-03-27 23:33:35,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid null) service to hadoop2/172.19.0.5:9000 beginning handshake with NN
2020-03-27 23:33:35,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid null) service to hadoop1/172.19.0.6:9000 beginning handshake with NN
2020-03-27 23:33:35,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid null) service to hadoop1/172.19.0.6:9000 successfully registered with NN
2020-03-27 23:33:35,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoop1/172.19.0.6:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-03-27 23:33:35,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop2/172.19.0.5:9000 successfully registered with NN
2020-03-27 23:33:35,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoop2/172.19.0.5:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-03-27 23:33:36,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop1/172.19.0.6:9000 with standby state
2020-03-27 23:33:36,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action : DNA_REGISTER from hadoop2/172.19.0.5:9000 with standby state
2020-03-27 23:33:36,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop2/172.19.0.5:9000 beginning handshake with NN
2020-03-27 23:33:36,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.6:9000 beginning handshake with NN
2020-03-27 23:33:36,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop2/172.19.0.5:9000 successfully registered with NN
2020-03-27 23:33:36,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.6:9000 successfully registered with NN
2020-03-27 23:33:36,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Unsuccessfully sent block report 0x22734c7498b,  containing 1 storage report(s), of which we sent 0. The reports had 31 total blocks and used 0 RPC(s). This took 4 msec to generate and 11 msecs for RPC and NN processing. Got back no commands.
2020-03-27 23:33:36,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Unsuccessfully sent block report 0x22734c74474,  containing 1 storage report(s), of which we sent 0. The reports had 31 total blocks and used 0 RPC(s). This took 4 msec to generate and 11 msecs for RPC and NN processing. Got back no commands.
2020-03-27 23:33:36,061 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.6:9000 is shutting down
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.UnregisteredNodeException): Data node DatanodeRegistration(172.19.0.6:50010, datanodeUuid=5c2745ab-8b04-406c-a9d7-c513e9d8983b, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-5e691286-4de5-4dde-800b-c02a7a8bf44a;nsid=1995885711;c=0) is attempting to report storage ID 5c2745ab-8b04-406c-a9d7-c513e9d8983b. Node 172.19.0.5:50010 is expected to serve this storage.
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanode(DatanodeManager.java:495)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:1791)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1315)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:163)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:28543)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.blockReport(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:199)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.blockReport(BPServiceActor.java:463)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:688)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
2020-03-27 23:33:36,061 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop2/172.19.0.5:9000 is shutting down
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.UnregisteredNodeException): Data node DatanodeRegistration(172.19.0.6:50010, datanodeUuid=5c2745ab-8b04-406c-a9d7-c513e9d8983b, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-5e691286-4de5-4dde-800b-c02a7a8bf44a;nsid=1995885711;c=0) is attempting to report storage ID 5c2745ab-8b04-406c-a9d7-c513e9d8983b. Node 172.19.0.5:50010 is expected to serve this storage.
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanode(DatanodeManager.java:495)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:1791)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1315)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:163)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:28543)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.blockReport(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:199)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.blockReport(BPServiceActor.java:463)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:688)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
2020-03-27 23:33:36,063 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop2/172.19.0.5:9000
2020-03-27 23:33:36,063 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b) service to hadoop1/172.19.0.6:9000
2020-03-27 23:33:36,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool BP-1961412683-172.17.0.32-1450036414523 (Datanode Uuid 5c2745ab-8b04-406c-a9d7-c513e9d8983b)
2020-03-27 23:33:36,165 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removing block pool BP-1961412683-172.17.0.32-1450036414523
2020-03-27 23:33:38,166 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-27 23:33:38,168 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-27 23:33:38,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 00:24:24,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 00:24:24,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 00:24:25,357 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 00:24:25,590 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 00:24:25,646 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 00:24:25,646 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 00:24:25,651 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 00:24:25,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 00:24:25,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 00:24:25,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 00:24:25,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 00:24:25,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 00:24:25,760 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 00:24:25,768 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 00:24:25,773 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 00:24:25,777 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 00:24:25,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 00:24:25,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 00:24:25,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 00:24:25,790 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36647
2020-03-28 00:24:25,791 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 00:24:25,950 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36647
2020-03-28 00:24:26,085 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 00:24:26,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 00:24:26,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 00:24:36,260 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 00:24:36,278 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 00:24:36,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 00:24:36,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 00:24:36,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 00:24:36,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 00:24:36,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 00:24:36,367 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 00:24:36,367 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 00:24:36,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 6194@hadoop1
2020-03-28 00:24:36,572 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; datanode clusterID = CID-5e691286-4de5-4dde-800b-c02a7a8bf44a
2020-03-28 00:24:36,580 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 6194@hadoop1
2020-03-28 00:24:36,581 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; datanode clusterID = CID-5e691286-4de5-4dde-800b-c02a7a8bf44a
2020-03-28 00:24:36,581 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 00:24:36,583 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 00:24:36,587 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 00:24:36,587 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 00:24:36,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 00:24:38,688 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 00:24:38,691 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 00:24:38,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 00:31:52,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 00:31:52,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 00:31:52,683 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 00:31:52,911 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 00:31:52,965 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 00:31:52,966 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 00:31:52,970 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 00:31:52,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 00:31:52,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 00:31:53,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 00:31:53,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 00:31:53,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 00:31:53,075 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 00:31:53,083 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 00:31:53,088 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 00:31:53,093 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 00:31:53,096 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 00:31:53,096 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 00:31:53,096 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 00:31:53,105 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44261
2020-03-28 00:31:53,106 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 00:31:53,258 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44261
2020-03-28 00:31:53,376 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 00:31:53,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 00:31:53,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 00:32:03,531 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 00:32:03,543 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 00:32:03,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 00:32:03,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 00:32:03,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 00:32:03,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 00:32:03,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 00:32:03,781 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 00:32:03,781 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 00:32:10,625 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 7643@hadoop1
2020-03-28 00:32:10,627 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; datanode clusterID = CID-5e691286-4de5-4dde-800b-c02a7a8bf44a
2020-03-28 00:32:10,628 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 7643@hadoop1
2020-03-28 00:32:10,629 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; datanode clusterID = CID-5e691286-4de5-4dde-800b-c02a7a8bf44a
2020-03-28 00:32:10,629 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 00:32:10,630 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 00:32:10,629 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 00:32:10,631 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 00:32:10,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 00:32:12,733 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 00:32:12,735 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 00:32:12,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 01:03:19,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 01:03:19,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 01:03:19,801 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 01:03:20,127 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 01:03:20,211 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 01:03:20,211 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 01:03:20,216 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 01:03:20,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 01:03:20,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 01:03:20,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 01:03:20,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 01:03:20,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 01:03:20,375 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 01:03:20,388 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 01:03:20,396 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 01:03:20,403 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 01:03:20,407 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 01:03:20,407 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 01:03:20,407 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 01:03:20,423 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39539
2020-03-28 01:03:20,423 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 01:03:20,634 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39539
2020-03-28 01:03:20,822 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 01:03:21,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 01:03:21,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 01:03:31,068 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 01:03:31,148 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 01:03:31,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 01:03:31,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 01:03:31,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 01:03:31,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 01:03:31,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 01:03:31,494 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 01:03:31,494 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 01:03:40,114 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 293@hadoop1
2020-03-28 01:03:40,116 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-root/dfs/data is not formatted for BP-1697387888-172.19.0.6-1585369004404
2020-03-28 01:03:40,116 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-03-28 01:03:40,309 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1697387888-172.19.0.6-1585369004404
2020-03-28 01:03:40,309 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1697387888-172.19.0.6-1585369004404
2020-03-28 01:03:40,310 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-root/dfs/data/current/BP-1697387888-172.19.0.6-1585369004404 is not formatted for BP-1697387888-172.19.0.6-1585369004404
2020-03-28 01:03:40,310 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-03-28 01:03:40,310 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1697387888-172.19.0.6-1585369004404 directory /tmp/hadoop-root/dfs/data/current/BP-1697387888-172.19.0.6-1585369004404/current
2020-03-28 01:03:40,314 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-03-28 01:03:40,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=422310944;bpid=BP-1697387888-172.19.0.6-1585369004404;lv=-56;nsInfo=lv=-63;cid=CID-afa2b6d3-b992-470f-8043-18eafb0b06c6;nsid=422310944;c=0;bpid=BP-1697387888-172.19.0.6-1585369004404;dnuuid=null
2020-03-28 01:03:40,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID b6bfed77-dbcd-4916-8cb4-e48605341c11
2020-03-28 01:03:40,415 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-69798513-3b9e-4b37-86a2-0254fdb26257
2020-03-28 01:03:40,415 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2020-03-28 01:03:40,454 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-03-28 01:03:40,455 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1697387888-172.19.0.6-1585369004404
2020-03-28 01:03:40,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1697387888-172.19.0.6-1585369004404 on volume /tmp/hadoop-root/dfs/data/current...
2020-03-28 01:03:40,500 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1697387888-172.19.0.6-1585369004404 on /tmp/hadoop-root/dfs/data/current: 39ms
2020-03-28 01:03:40,504 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1697387888-172.19.0.6-1585369004404: 49ms
2020-03-28 01:03:40,509 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1697387888-172.19.0.6-1585369004404 on volume /tmp/hadoop-root/dfs/data/current...
2020-03-28 01:03:40,509 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1697387888-172.19.0.6-1585369004404 on volume /tmp/hadoop-root/dfs/data/current: 0ms
2020-03-28 01:03:40,512 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2020-03-28 01:03:40,687 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1697387888-172.19.0.6-1585369004404 on volume /tmp/hadoop-root/dfs/data
2020-03-28 01:03:40,689 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1585382459689 with interval 21600000
2020-03-28 01:03:40,690 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-69798513-3b9e-4b37-86a2-0254fdb26257): finished scanning block pool BP-1697387888-172.19.0.6-1585369004404
2020-03-28 01:03:40,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid null) service to hadoop2/172.19.0.5:9000 beginning handshake with NN
2020-03-28 01:03:40,692 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid null) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:03:40,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid null) service to hadoop2/172.19.0.5:9000 successfully registered with NN
2020-03-28 01:03:40,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoop2/172.19.0.5:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-03-28 01:03:40,741 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-69798513-3b9e-4b37-86a2-0254fdb26257): no suitable block pools found to scan.  Waiting 1814399946 ms.
2020-03-28 01:03:40,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x71198a560a0,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 52 msecs for RPC and NN processing. Got back no commands.
2020-03-28 01:03:45,695 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:03:50,699 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:03:55,704 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:00,707 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:05,709 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:10,711 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:15,714 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:20,717 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:25,720 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:30,722 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:35,726 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:40,729 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:45,733 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:50,739 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:04:55,742 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:00,745 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:05,748 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:10,751 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:15,753 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:20,757 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:25,760 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:30,763 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:35,766 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:40,769 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:45,772 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:50,775 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:05:55,778 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:00,781 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:05,785 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:10,788 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:15,791 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:20,794 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:25,797 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:30,801 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:35,804 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:40,807 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:45,810 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:50,813 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:06:55,816 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:00,819 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:05,822 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:10,825 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:15,828 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:20,832 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:25,835 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:30,838 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:35,841 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:40,844 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:45,847 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:50,850 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:07:55,854 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:00,857 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:05,860 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:10,863 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:15,866 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:20,869 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:25,872 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:30,886 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:35,889 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:40,892 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:45,895 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:50,898 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:08:55,902 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:00,905 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:05,908 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:10,911 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:15,914 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:20,917 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:25,920 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:30,923 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:35,925 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:40,928 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:45,931 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:50,934 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:09:55,937 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:00,940 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:05,944 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:10,947 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:15,950 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:20,953 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:25,956 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool BP-1697387888-172.19.0.6-1585369004404 (Datanode Uuid b6bfed77-dbcd-4916-8cb4-e48605341c11) service to hadoop1/172.19.0.6:9000 Blockpool ID mismatch: previously connected to Blockpool ID BP-1697387888-172.19.0.6-1585369004404 but now connected to Blockpool ID BP-35910653-172.19.0.6-1585370365860
2020-03-28 01:10:28,420 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "hadoop1/172.19.0.6"; destination host is: "hadoop2":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy13.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2020-03-28 01:10:30,958 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:10:32,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop2/172.19.0.5:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:10:33,178 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-03-28 01:10:33,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 01:17:59,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 01:17:59,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 01:17:59,640 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 01:17:59,880 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 01:17:59,934 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 01:17:59,934 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 01:17:59,939 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 01:17:59,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 01:17:59,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 01:17:59,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 01:17:59,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 01:17:59,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 01:18:00,046 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 01:18:00,054 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 01:18:00,059 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 01:18:00,063 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 01:18:00,066 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 01:18:00,066 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 01:18:00,066 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 01:18:00,077 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39041
2020-03-28 01:18:00,077 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 01:18:00,232 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39041
2020-03-28 01:18:00,354 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 01:18:00,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 01:18:00,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 01:18:10,516 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 01:18:10,533 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 01:18:10,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 01:18:10,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 01:18:10,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 01:18:10,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 01:18:10,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 01:18:10,612 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 01:18:10,613 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 01:18:17,568 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 244@hadoop1
2020-03-28 01:18:17,570 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-624e4a3e-e8ec-4296-ab33-6007a63b3e69; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:18:17,570 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: Cluster IDs not matched: dn cid=CID-624e4a3e-e8ec-4296-ab33-6007a63b3e69 but ns cid=CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; bpid=BP-1697387888-172.19.0.6-1585369004404
	at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:717)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1319)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:18:17,570 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:18:17,572 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 01:18:17,572 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 01:18:17,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 01:18:19,674 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 01:18:19,676 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 01:18:19,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 01:21:44,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 01:21:44,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 01:21:44,507 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 01:21:44,737 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 01:21:44,791 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 01:21:44,791 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 01:21:44,795 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 01:21:44,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 01:21:44,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 01:21:44,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 01:21:44,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 01:21:44,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 01:21:44,901 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 01:21:44,909 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 01:21:44,914 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 01:21:44,919 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 01:21:44,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 01:21:44,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 01:21:44,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 01:21:44,932 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41811
2020-03-28 01:21:44,932 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 01:21:45,093 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41811
2020-03-28 01:21:45,208 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 01:21:45,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 01:21:45,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 01:21:55,369 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 01:21:55,381 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 01:21:55,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 01:21:55,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 01:21:55,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 01:21:55,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 01:21:55,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 01:21:55,464 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 01:21:55,464 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 01:21:55,661 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 278@hadoop1
2020-03-28 01:21:55,662 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-624e4a3e-e8ec-4296-ab33-6007a63b3e69; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:21:55,663 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:21:55,663 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: Cluster IDs not matched: dn cid=CID-624e4a3e-e8ec-4296-ab33-6007a63b3e69 but ns cid=CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; bpid=BP-1697387888-172.19.0.6-1585369004404
	at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:717)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1319)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:21:55,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 01:21:55,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 01:21:55,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 01:21:57,766 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 01:21:57,767 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 01:21:57,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 01:35:14,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 01:35:14,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 01:35:14,799 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 01:35:15,039 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 01:35:15,094 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 01:35:15,094 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 01:35:15,099 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 01:35:15,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 01:35:15,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 01:35:15,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 01:35:15,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 01:35:15,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 01:35:15,206 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 01:35:15,214 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 01:35:15,218 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 01:35:15,223 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 01:35:15,226 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 01:35:15,226 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 01:35:15,226 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 01:35:15,236 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40897
2020-03-28 01:35:15,236 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 01:35:15,388 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40897
2020-03-28 01:35:15,525 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 01:35:15,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 01:35:15,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 01:35:25,693 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 01:35:25,704 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 01:35:25,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 01:35:25,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 01:35:25,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 01:35:25,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 01:35:25,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 01:35:25,772 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 01:35:25,772 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 01:35:25,970 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 1417@hadoop1
2020-03-28 01:35:25,972 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-624e4a3e-e8ec-4296-ab33-6007a63b3e69; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:35:25,972 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:35:25,972 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: Cluster IDs not matched: dn cid=CID-624e4a3e-e8ec-4296-ab33-6007a63b3e69 but ns cid=CID-afa2b6d3-b992-470f-8043-18eafb0b06c6; bpid=BP-1697387888-172.19.0.6-1585369004404
	at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:717)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1319)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:35:25,974 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 01:35:25,974 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 01:35:26,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 01:35:28,075 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 01:35:28,078 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 01:35:28,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 01:43:30,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 01:43:30,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 01:43:31,162 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 01:43:31,390 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 01:43:31,444 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 01:43:31,444 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 01:43:31,448 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 01:43:31,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 01:43:31,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 01:43:31,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 01:43:31,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 01:43:31,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 01:43:31,552 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 01:43:31,561 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 01:43:31,565 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 01:43:31,570 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 01:43:31,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 01:43:31,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 01:43:31,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 01:43:31,583 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41359
2020-03-28 01:43:31,583 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 01:43:31,739 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41359
2020-03-28 01:43:31,864 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 01:43:31,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 01:43:31,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 01:43:42,028 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 01:43:42,042 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 01:43:42,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 01:43:42,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 01:43:42,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 01:43:42,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 01:43:42,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 01:43:42,136 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 01:43:42,136 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 01:43:42,359 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 2706@hadoop1
2020-03-28 01:43:42,362 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:43:42,362 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 All specified directories are failed to load.
2020-03-28 01:43:48,821 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 2706@hadoop1
2020-03-28 01:43:48,822 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:43:48,823 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:43:48,825 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 01:43:53,940 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:43:59,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:00,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:01,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:02,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:03,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:04,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:05,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:06,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:07,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:08,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:08,952 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:44:14,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:15,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:16,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:17,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:18,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:19,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:20,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:21,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:22,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:23,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:23,961 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:44:29,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:30,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:31,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:32,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:33,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:34,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:35,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:36,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:37,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:38,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:38,970 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:44:44,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:45,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:46,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:47,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:48,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:49,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:50,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:51,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:52,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:53,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:44:53,979 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:44:59,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:00,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:01,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:02,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:03,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:04,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:05,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:06,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:07,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:08,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:08,988 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:45:14,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:15,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:16,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:17,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:18,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:19,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:20,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:21,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:22,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:23,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:23,998 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:45:29,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:31,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:32,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:33,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:34,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:35,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:36,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:37,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:45:37,596 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-03-28 01:45:37,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 01:46:08,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 01:46:08,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 01:46:09,352 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 01:46:09,584 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 01:46:09,638 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 01:46:09,638 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 01:46:09,644 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 01:46:09,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 01:46:09,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 01:46:09,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 01:46:09,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 01:46:09,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 01:46:09,749 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 01:46:09,757 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 01:46:09,762 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 01:46:09,766 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 01:46:09,769 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 01:46:09,769 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 01:46:09,769 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 01:46:09,779 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45995
2020-03-28 01:46:09,779 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 01:46:09,935 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45995
2020-03-28 01:46:10,061 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 01:46:10,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 01:46:10,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 01:46:20,225 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 01:46:20,242 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 01:46:20,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 01:46:20,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 01:46:20,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 01:46:20,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 01:46:20,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 01:46:20,324 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 01:46:20,324 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 01:46:27,147 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 3832@hadoop1
2020-03-28 01:46:27,149 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:46:27,149 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 All specified directories are failed to load.
2020-03-28 01:46:27,213 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 3832@hadoop1
2020-03-28 01:46:27,213 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:46:27,214 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:46:27,215 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 01:46:37,387 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:46:43,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:44,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:45,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:46,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:47,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:48,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:49,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:50,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:51,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:52,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:52,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:46:58,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:46:59,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:00,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:01,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:02,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:03,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:04,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:05,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:06,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:07,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:07,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:47:13,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:14,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:15,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:16,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:17,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:18,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:19,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:20,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:21,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:22,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:22,415 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:47:28,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:29,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:30,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:31,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:32,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:33,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:34,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:35,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:36,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:37,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:37,424 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:47:43,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:44,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:45,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:46,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:47,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:48,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:49,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:50,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:51,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:52,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:52,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:47:58,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:47:59,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:00,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:01,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:02,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:03,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:04,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:05,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:06,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:07,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:07,442 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:48:13,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:14,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:15,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:16,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:17,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:18,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:19,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:20,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:21,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:22,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:22,451 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:48:28,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:29,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:30,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:31,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:32,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:33,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:34,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:35,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:36,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:37,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:37,459 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:48:43,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:44,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:45,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:46,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:47,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:48,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:49,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:50,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:51,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:52,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:52,469 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:48:58,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:48:59,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:00,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:01,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:02,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:03,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:04,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:05,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:06,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:07,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:07,478 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:49:13,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:14,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:15,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:16,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:17,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:18,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:19,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:20,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:21,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:22,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:22,487 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:49:28,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:29,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:30,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:31,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:32,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:33,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:34,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:35,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:36,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:37,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:37,496 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:49:43,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:44,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:45,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:46,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:47,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:48,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:49,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:50,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:51,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:52,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:52,505 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:49:58,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:49:59,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:00,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:01,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:02,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:03,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:04,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:05,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:06,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:07,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:07,514 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:50:13,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:14,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:15,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:16,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:17,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:18,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:19,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:20,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:21,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:22,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:22,522 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:50:28,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:29,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:30,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:31,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:32,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:33,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:34,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:35,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:36,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:37,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:37,534 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:50:43,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:44,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:45,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:46,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:47,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:48,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:49,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:50,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:51,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:52,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:52,544 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:50:58,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:50:59,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:00,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:01,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:02,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:03,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:04,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:05,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:06,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:07,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:07,553 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:51:13,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:14,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:15,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:16,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:17,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:18,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:19,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:20,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:21,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:22,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:22,562 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:51:28,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:29,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:30,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:31,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:32,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:33,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:34,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:35,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:36,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:37,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:37,572 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:51:43,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:44,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:45,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:46,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:47,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:48,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:49,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:50,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:51,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:52,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:52,581 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:51:58,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:51:59,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:00,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:01,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:02,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:03,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:04,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:05,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:06,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:07,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:07,591 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:52:13,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:14,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:15,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:16,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:17,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:18,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:19,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:20,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:21,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:22,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:22,600 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:52:28,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:29,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:30,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:31,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:32,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:33,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:34,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:35,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:36,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:37,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:37,610 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:52:43,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:44,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:45,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:46,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:47,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:48,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:49,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:50,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:51,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:52,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:52,619 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:52:58,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:52:59,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:00,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:01,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:02,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:03,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:04,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:05,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:06,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:07,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:07,629 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:53:13,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:14,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:15,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:16,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:17,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:18,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:19,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:20,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:21,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:22,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:22,638 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:53:28,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:29,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:30,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:31,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:32,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:33,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:34,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:35,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:36,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:37,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:37,649 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:53:43,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:44,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:45,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:46,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:47,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:48,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:49,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:50,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:51,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:52,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:52,659 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:53:58,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:53:59,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:00,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:01,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:02,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:03,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:04,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:05,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:06,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:07,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:07,669 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:54:13,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:14,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:15,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:16,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:17,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:18,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:19,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:20,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:21,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:22,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:22,678 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:54:28,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:29,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:30,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:31,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:32,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:33,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:34,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:35,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:36,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:37,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:37,687 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:54:43,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:44,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:45,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:46,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:47,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:48,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:49,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:50,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:51,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:52,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:52,696 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:54:58,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:54:59,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:00,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:01,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:02,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:03,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:04,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:05,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:06,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:07,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:07,706 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:55:13,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:14,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:15,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:16,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:17,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:18,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:19,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:20,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:21,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:22,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:22,715 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:55:28,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:29,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:30,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:31,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:32,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:33,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:34,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:35,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:36,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:37,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:37,724 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:55:43,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:44,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:45,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:46,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:47,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:48,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:49,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:50,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:51,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:52,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:52,733 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:55:58,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:55:59,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:00,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:01,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:02,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:03,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:04,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:05,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:06,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:07,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:07,743 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:56:13,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:14,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:15,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:16,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:17,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:18,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:19,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:20,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:21,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:22,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:22,753 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:56:28,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:29,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:30,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:31,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:32,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:33,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:34,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:35,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:36,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:37,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:37,762 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.6:9000
2020-03-28 01:56:43,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:44,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:45,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:56:46,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.6:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-28 01:57:06,206 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 3832@hadoop1
2020-03-28 01:57:06,207 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 01:57:06,207 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 01:57:06,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 01:57:06,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 01:57:08,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 01:57:08,210 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 01:57:08,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 02:00:12,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 02:00:12,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 02:00:13,055 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 02:00:13,301 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 02:00:13,356 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 02:00:13,356 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 02:00:13,361 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 02:00:13,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 02:00:13,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 02:00:13,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 02:00:13,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 02:00:13,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 02:00:13,475 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 02:00:13,484 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 02:00:13,489 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 02:00:13,494 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 02:00:13,496 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 02:00:13,497 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 02:00:13,497 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 02:00:13,508 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45339
2020-03-28 02:00:13,508 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 02:00:13,675 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45339
2020-03-28 02:00:13,785 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 02:00:13,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 02:00:13,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 02:00:23,948 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 02:00:23,960 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 02:00:23,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 02:00:24,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 02:00:24,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 02:00:24,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 02:00:24,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 02:00:24,048 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 02:00:24,048 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 02:00:31,099 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 5469@hadoop1
2020-03-28 02:00:31,101 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 02:00:31,103 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 5469@hadoop1
2020-03-28 02:00:31,103 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 02:00:31,104 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 02:00:31,104 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 02:00:31,106 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 02:00:31,106 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 02:00:31,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 02:00:33,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 02:00:33,210 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 02:00:33,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 02:15:12,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 02:15:12,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 02:15:12,705 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 02:15:12,938 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 02:15:12,993 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 02:15:12,993 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 02:15:12,998 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 02:15:12,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 02:15:13,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 02:15:13,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 02:15:13,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 02:15:13,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 02:15:13,104 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 02:15:13,112 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 02:15:13,117 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 02:15:13,122 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 02:15:13,125 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 02:15:13,125 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 02:15:13,125 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 02:15:13,135 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42497
2020-03-28 02:15:13,135 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 02:15:13,291 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42497
2020-03-28 02:15:13,424 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 02:15:13,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 02:15:13,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 02:15:23,584 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 02:15:23,596 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 02:15:23,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 02:15:23,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 02:15:23,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 02:15:23,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 02:15:23,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 02:15:23,666 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 02:15:23,666 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 02:15:30,602 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 7353@hadoop1
2020-03-28 02:15:30,604 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 02:15:30,606 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 7353@hadoop1
2020-03-28 02:15:30,606 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 02:15:30,607 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 02:15:30,607 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 02:15:30,608 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 02:15:30,608 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 02:15:30,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 02:15:32,710 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 02:15:32,712 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 02:15:32,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-28 02:17:31,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-28 02:17:31,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 02:17:31,513 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-28 02:17:31,745 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 02:17:31,799 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 02:17:31,799 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-28 02:17:31,804 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-28 02:17:31,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-28 02:17:31,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-28 02:17:31,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-28 02:17:31,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-28 02:17:31,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-28 02:17:31,911 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 02:17:31,919 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 02:17:31,924 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-28 02:17:31,928 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 02:17:31,931 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-28 02:17:31,931 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 02:17:31,931 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 02:17:31,941 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37809
2020-03-28 02:17:31,941 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 02:17:32,100 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37809
2020-03-28 02:17:32,231 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-28 02:17:32,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-28 02:17:32,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-28 02:17:42,396 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-28 02:17:42,410 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-28 02:17:42,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-28 02:17:42,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-28 02:17:42,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-28 02:17:42,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000 starting to offer service
2020-03-28 02:17:42,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000 starting to offer service
2020-03-28 02:17:42,503 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-28 02:17:42,503 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 02:17:42,702 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 8339@hadoop1
2020-03-28 02:17:42,704 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 02:17:42,705 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 8339@hadoop1
2020-03-28 02:17:42,706 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-28 02:17:42,706 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 02:17:42,706 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-28 02:17:42,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.6:9000
2020-03-28 02:17:42,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.5:9000
2020-03-28 02:17:42,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-28 02:17:44,809 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-28 02:17:44,812 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-28 02:17:44,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.6
************************************************************/
2020-03-31 09:08:04,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-03-31 09:08:04,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-31 09:08:05,286 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-03-31 09:08:05,646 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-31 09:08:05,731 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-31 09:08:05,731 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-31 09:08:05,738 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-31 09:08:05,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-03-31 09:08:05,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-31 09:08:05,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-03-31 09:08:05,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-03-31 09:08:05,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-03-31 09:08:05,906 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-31 09:08:05,920 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-31 09:08:05,930 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-31 09:08:05,942 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-31 09:08:05,946 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-31 09:08:05,947 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-31 09:08:05,947 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-31 09:08:05,963 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38139
2020-03-31 09:08:05,963 INFO org.mortbay.log: jetty-6.1.26
2020-03-31 09:08:06,228 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38139
2020-03-31 09:08:06,386 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-03-31 09:08:06,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-03-31 09:08:06,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-31 09:08:16,596 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-03-31 09:08:16,623 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-03-31 09:08:16,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-03-31 09:08:16,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-03-31 09:08:16,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-03-31 09:08:16,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.3:9000 starting to offer service
2020-03-31 09:08:16,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.2:9000 starting to offer service
2020-03-31 09:08:16,837 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-31 09:08:16,849 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-03-31 09:08:25,665 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 366@hadoop1
2020-03-31 09:08:25,676 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-31 09:08:25,685 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 366@hadoop1
2020-03-31 09:08:25,686 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-7b7242c3-1806-4aad-a53d-bddbd1a0786e; datanode clusterID = CID-afa2b6d3-b992-470f-8043-18eafb0b06c6
2020-03-31 09:08:25,703 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.2:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-31 09:08:25,705 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.2:9000
2020-03-31 09:08:25,705 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.3:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:477)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:316)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)
	at java.lang.Thread.run(Thread.java:745)
2020-03-31 09:08:25,706 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2/172.19.0.3:9000
2020-03-31 09:08:25,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-03-31 09:08:27,823 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-03-31 09:08:27,825 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-03-31 09:08:27,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoop1/172.19.0.2
************************************************************/
2020-04-01 07:14:31,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoop1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_71
************************************************************/
2020-04-01 07:14:31,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-04-01 07:14:32,113 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-01 07:14:32,351 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-04-01 07:14:32,405 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-04-01 07:14:32,406 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-04-01 07:14:32,410 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-04-01 07:14:32,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop1
2020-04-01 07:14:32,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-04-01 07:14:32,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-04-01 07:14:32,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-04-01 07:14:32,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-04-01 07:14:32,517 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-04-01 07:14:32,525 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-01 07:14:32,530 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-04-01 07:14:32,534 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-01 07:14:32,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-01 07:14:32,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-01 07:14:32,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-01 07:14:32,547 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39223
2020-04-01 07:14:32,547 INFO org.mortbay.log: jetty-6.1.26
2020-04-01 07:14:32,700 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39223
2020-04-01 07:14:32,838 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-04-01 07:14:32,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-04-01 07:14:32,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-04-01 07:14:43,008 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-04-01 07:14:43,019 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-04-01 07:14:43,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-04-01 07:14:43,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1
2020-04-01 07:14:43,080 WARN org.apache.hadoop.hdfs.DFSUtil: Namenode for ns1 remains unresolved for ID nn1.  Check your hdfs-site.xml file to ensure namenodes are configured properly.
2020-04-01 07:14:43,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1
2020-04-01 07:14:43,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop2:9000 starting to offer service
2020-04-01 07:14:43,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoop1/172.19.0.2:9000 starting to offer service
2020-04-01 07:14:43,097 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-04-01 07:14:43,097 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-04-01 07:14:43,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:14:44,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:45,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:46,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:47,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:48,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:14:48,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:49,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:50,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:51,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:52,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:53,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:14:53,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:14:53,199 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:14:58,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:14:59,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:00,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:01,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:02,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:03,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:03,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:04,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:05,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:06,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:07,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:08,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:08,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:08,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:15:13,179 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:14,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:15,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:16,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:17,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:18,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:18,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:19,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:20,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:21,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:22,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:23,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:23,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:23,216 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:15:28,181 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:29,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:30,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:31,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:32,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:33,181 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:33,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:34,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:35,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:36,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:37,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:38,182 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:38,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:38,225 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:15:43,182 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:44,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:45,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:46,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:47,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:48,183 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:48,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:49,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:50,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:51,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:52,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:53,183 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:53,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:15:53,233 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:15:58,186 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:15:59,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:00,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:01,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:02,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:03,186 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:03,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:04,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:05,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:06,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:07,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:08,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:08,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:08,242 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:16:13,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:14,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:15,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:16,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:17,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:18,188 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:18,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:19,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:20,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:21,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:22,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:23,188 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:23,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:23,251 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:16:28,189 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:29,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:30,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:31,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:32,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:33,189 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:33,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:34,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:35,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:36,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:37,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:38,190 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:38,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:38,260 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:16:43,190 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:44,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:45,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:46,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:47,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:48,191 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:48,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:49,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:50,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:51,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:52,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:53,191 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:53,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:16:53,268 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:16:58,192 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:16:59,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:00,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:01,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:02,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:03,192 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:03,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:04,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:05,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:06,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:07,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:08,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:08,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:08,276 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:17:13,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:14,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:15,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:16,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:17,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:18,194 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:18,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:19,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:20,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:21,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:22,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:23,194 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:23,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:23,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:17:28,195 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:29,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:30,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:31,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:32,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:33,195 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:33,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:34,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:35,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:36,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:37,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:38,196 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:38,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:38,294 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:17:43,197 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:44,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:45,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:46,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:47,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:48,197 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:48,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:49,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:50,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:51,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:52,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:53,198 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:53,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:17:53,303 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:17:58,198 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:17:59,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:00,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:01,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:02,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:03,199 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:03,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:04,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:05,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:06,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:07,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:08,199 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:08,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:08,312 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:18:13,200 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:14,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:15,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:16,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:17,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:18,200 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:18,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:19,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:20,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:21,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:22,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:23,201 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:23,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:23,321 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:18:28,201 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:29,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:30,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:31,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:32,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:33,202 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:33,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:34,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:35,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:36,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:37,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:38,202 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:38,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:38,331 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:18:43,203 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:44,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:45,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:46,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:47,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:48,204 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:48,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:49,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:50,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:51,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:52,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:53,204 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:53,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:18:53,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:18:58,204 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:18:59,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:00,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:01,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:02,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:03,205 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:03,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:04,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:05,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:06,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:07,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:08,206 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:08,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:08,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:19:13,206 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:14,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:15,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:16,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:17,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:18,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:18,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:19,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:20,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:21,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:22,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:23,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:23,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:23,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:19:28,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:29,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:30,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:31,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:32,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:33,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:33,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:34,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:35,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:36,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:37,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:38,209 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:38,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:38,366 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:19:43,209 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:44,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:45,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:46,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:47,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:48,210 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:48,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:49,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:50,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:51,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:52,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:53,210 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:53,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:19:53,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:19:58,211 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:19:59,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:00,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:01,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:02,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:03,211 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:03,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:04,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:05,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:06,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:07,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:08,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:08,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:08,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:20:13,213 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:14,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:15,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:16,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:17,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:18,213 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:18,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:19,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:20,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:21,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:22,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:23,213 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:23,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:23,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:20:28,214 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:29,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:30,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:31,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:32,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:33,214 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:33,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:34,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:35,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:36,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:37,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:38,215 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:38,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:38,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:20:43,215 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:44,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:45,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:46,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:47,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:48,216 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:48,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:49,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:50,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:51,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:52,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:53,216 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:53,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:20:53,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:20:58,217 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:20:59,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:00,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:01,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:02,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:03,217 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:03,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:04,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:05,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:06,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:07,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:08,218 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:08,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:08,418 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:21:13,218 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:14,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:15,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:16,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:17,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:18,219 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:18,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:19,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:20,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:21,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:22,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:23,220 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:23,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:23,427 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:21:28,220 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:29,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:30,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:31,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:32,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:33,221 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:33,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:34,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:35,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:36,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:37,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:38,221 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:38,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:38,435 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:21:43,222 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:44,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:45,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:46,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:47,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:48,222 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:48,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:49,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:50,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:51,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:52,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:53,223 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:53,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:21:53,445 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:21:58,223 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:21:59,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:00,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:01,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:02,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:03,224 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:03,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:04,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:05,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:06,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:07,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:08,224 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:08,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:08,454 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:22:13,225 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:14,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:15,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:16,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:17,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:18,225 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:18,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:19,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:20,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:21,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:22,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:23,226 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:23,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:23,462 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:22:28,226 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:29,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:30,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:31,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:32,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:33,227 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:33,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:34,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:35,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:36,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:37,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:38,227 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:38,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:38,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:22:43,228 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:44,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:45,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:46,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:47,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:48,229 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:48,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:49,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:50,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:51,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:52,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:53,229 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:53,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:22:53,480 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:22:58,230 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:22:59,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:00,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:01,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:02,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:03,230 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:03,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:04,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:05,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:06,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:07,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:08,231 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:08,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:08,489 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:23:13,231 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:14,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:15,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:16,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:17,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:18,232 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:18,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:19,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:20,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:21,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:22,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:23,232 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:23,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:23,497 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:23:28,233 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:29,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:30,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:31,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:32,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:33,233 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:33,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:34,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:35,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:36,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:37,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:38,234 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:38,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:38,506 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:23:43,234 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:44,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:45,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:46,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:47,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:48,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:48,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:49,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:50,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:51,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:52,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:53,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:53,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:23:53,515 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:23:58,236 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:23:59,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:00,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:01,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:02,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:03,236 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:03,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:04,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:05,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:06,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:07,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:08,237 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:08,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:08,523 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:24:13,237 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:14,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:15,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:16,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:17,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:18,238 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:18,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:19,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:20,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:21,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:22,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:23,239 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:23,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:23,532 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:24:28,239 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:29,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:30,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:31,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:32,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:33,240 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:33,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:34,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:35,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:36,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:37,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:38,240 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:38,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:38,541 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:24:43,241 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:44,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:45,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:46,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:47,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:48,242 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:48,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:49,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:50,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:51,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:52,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:53,242 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:53,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:24:53,550 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:24:58,243 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:24:59,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:00,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:01,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:02,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:03,243 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:03,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:04,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:05,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:06,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:07,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:08,244 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:08,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:08,559 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:25:13,245 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:14,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:15,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:16,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:17,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:18,245 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:18,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:19,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:20,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:21,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:22,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:23,245 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:23,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:23,568 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:25:28,246 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:29,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:30,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:31,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:32,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:33,247 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:33,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:34,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:35,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:36,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:37,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:38,247 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:38,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:38,576 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:25:43,248 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:44,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:45,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:46,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:47,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:48,248 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:48,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:49,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:50,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:51,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:52,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:53,249 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:53,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:25:53,585 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:25:58,249 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:25:59,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:00,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:01,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:02,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:03,250 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:03,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:04,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:05,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:06,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:07,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:08,250 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:08,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:08,594 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:26:13,251 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:14,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:15,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:16,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:17,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:18,251 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:18,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:19,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:20,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:21,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:22,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:23,252 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:23,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:23,603 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:26:28,252 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:29,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:30,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:31,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:32,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:33,253 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:33,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:34,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:35,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:36,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:37,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:38,254 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:38,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:38,612 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:26:43,254 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:44,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:45,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:46,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:47,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:48,255 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:48,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:49,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:50,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:51,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:52,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:53,255 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:53,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:26:53,620 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:26:58,256 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:26:59,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:00,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:01,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:02,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:03,256 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:03,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:04,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:05,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:06,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:07,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:08,257 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:08,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:08,629 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:27:13,257 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:14,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:15,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:16,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:17,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:18,258 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:18,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:19,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:20,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:21,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:22,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:23,258 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:23,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:23,638 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:27:28,259 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:29,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:30,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:31,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:32,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:33,259 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:33,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:34,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:35,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:36,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:37,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:38,260 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:38,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:38,646 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:27:43,260 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:44,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:45,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:46,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:47,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:48,261 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:48,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:49,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:50,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:51,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:52,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:53,261 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:53,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:27:53,655 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:27:58,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:27:59,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:00,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:01,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:02,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:03,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:03,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:04,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:05,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:06,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:07,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:08,263 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:08,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:08,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:28:13,263 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:14,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:15,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:16,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:17,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:18,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:18,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:19,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:20,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:21,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:22,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:23,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:23,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:23,673 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:28:28,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:29,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:30,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:31,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:32,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:33,266 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:33,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:34,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:35,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:36,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:37,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:38,266 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:38,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:38,682 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:28:43,267 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:44,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:45,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:46,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:47,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:48,267 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:48,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:49,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:50,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:51,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:52,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:53,268 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:53,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:28:53,690 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:28:58,268 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:28:59,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:00,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:01,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:02,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:03,269 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:03,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:04,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:05,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:06,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:07,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:08,269 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:08,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:08,699 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:29:13,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:14,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:15,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:16,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:17,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:18,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:18,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:19,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:20,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:21,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:22,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:23,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:23,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:23,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:29:28,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:29,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:30,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:31,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:32,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:33,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:33,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:34,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:35,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:36,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:37,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:38,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:38,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:38,717 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:29:43,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:44,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:45,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:46,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:47,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:48,274 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:48,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:49,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:50,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:51,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:52,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:53,274 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:53,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:29:53,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:29:58,275 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:29:59,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:00,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:01,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:02,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:03,275 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:03,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:04,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:05,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:06,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:07,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:08,276 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:08,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:08,734 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:30:13,276 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:14,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:15,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:16,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:17,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:18,276 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:18,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:19,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:20,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:21,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:22,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:23,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:23,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:23,743 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:30:28,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:29,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:30,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:31,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:32,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:33,278 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:33,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:34,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:35,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:36,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:37,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:38,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:38,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:38,751 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:30:43,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:44,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:45,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:46,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:47,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:48,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:48,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:49,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:50,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:51,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:52,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:53,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:53,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:30:53,760 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:30:58,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:30:59,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:00,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:01,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:02,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:03,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:03,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:04,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:05,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:06,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:07,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:08,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:08,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:08,769 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:31:13,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:14,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:15,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:16,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:17,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:18,283 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:18,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:19,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:20,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:21,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:22,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:23,283 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:23,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:23,778 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:31:28,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:29,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:30,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:31,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:32,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:33,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:33,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:34,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:35,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:36,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:37,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:38,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:38,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:38,786 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:31:43,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:44,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:45,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:46,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:47,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:48,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:48,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:49,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:50,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:51,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:52,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:53,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:53,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:31:53,795 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:31:58,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:31:59,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:00,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:01,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:02,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:03,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:03,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:04,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:05,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:06,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:07,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:08,288 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:08,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:08,805 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:32:13,288 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:14,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:15,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:16,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:17,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:18,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:18,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:19,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:20,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:21,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:22,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:23,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:23,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:23,814 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:32:28,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:29,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:30,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:31,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:32,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:33,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:33,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:34,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:35,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:36,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:37,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:38,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:38,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:38,822 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:32:43,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:44,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:45,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:46,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:47,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:48,292 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:48,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:49,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:50,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:51,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:52,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:53,292 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:53,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:32:53,831 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:32:58,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:32:59,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:00,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:01,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:02,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:03,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:03,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:04,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:05,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:06,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:07,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:08,294 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:08,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:08,840 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:33:13,294 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:14,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:15,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:16,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:17,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:18,295 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:18,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:19,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:20,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:21,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:22,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:23,295 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:23,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:23,848 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:33:28,296 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:29,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:30,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:31,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:32,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:33,296 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:33,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:34,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:35,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:36,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:37,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:38,297 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:38,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:38,856 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:33:43,297 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:44,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:45,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:46,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:47,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:48,298 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:48,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:49,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:50,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:51,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:52,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:53,298 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:53,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:33:53,865 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:33:58,299 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:33:59,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:00,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:01,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:02,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:03,299 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:03,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:04,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:05,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:06,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:07,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:08,300 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:08,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:08,874 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:34:13,300 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:14,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:15,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:16,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:17,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:18,301 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:18,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:19,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:20,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:21,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:22,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:23,301 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:23,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:23,883 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:34:28,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:29,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:30,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:31,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:32,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:33,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:33,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:34,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:35,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:36,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:37,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:38,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:38,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:38,890 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:34:43,303 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:44,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:45,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:46,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:47,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:48,303 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:48,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:49,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:50,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:51,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:52,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:53,304 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:53,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:34:53,898 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:34:58,304 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:34:59,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:00,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:01,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:02,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:03,305 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:03,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:04,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:05,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:06,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:07,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:08,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:08,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:08,907 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:35:13,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:14,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:15,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:16,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:17,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:18,307 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:18,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:19,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:20,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:21,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:22,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:23,307 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:23,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:23,917 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:35:28,308 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:29,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:30,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:31,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:32,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:33,308 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:33,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:34,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:35,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:36,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:37,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:38,309 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:38,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:38,925 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:35:43,309 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:44,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:45,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:46,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:47,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:48,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:48,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:49,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:50,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:51,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:52,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:53,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:53,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:35:53,934 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:35:58,311 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:35:59,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:00,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:01,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:02,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:03,311 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:03,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:04,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:05,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:06,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:07,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:08,312 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:08,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:08,943 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:36:13,312 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:14,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:15,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:16,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:17,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:18,313 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:18,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:19,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:20,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:21,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:22,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:23,313 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:23,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:23,952 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:36:28,314 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:29,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:30,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:31,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:32,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:33,314 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:33,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:34,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:35,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:36,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:37,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:38,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:38,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:38,960 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:36:43,316 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:44,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:45,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:46,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:47,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:48,316 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:48,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:49,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:50,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:51,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:52,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:53,316 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:53,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:36:53,968 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:36:58,317 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:36:59,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:00,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:01,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:02,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:03,317 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:03,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:04,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:05,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:06,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:07,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:08,318 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:08,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:08,977 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:37:13,319 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:14,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:15,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:16,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:17,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:18,319 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:18,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:19,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:20,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:21,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:22,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:23,320 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:23,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:23,986 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:37:28,320 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:29,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:30,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:31,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:32,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:33,321 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:33,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:34,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:35,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:36,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:37,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:38,321 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:38,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:38,995 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:37:43,322 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:44,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:45,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:46,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:47,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:48,322 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:48,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:50,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:51,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:52,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:53,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:53,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:37:54,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:37:54,003 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:37:58,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:00,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:01,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:02,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:03,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:03,324 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:04,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:05,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:06,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:07,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:08,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:08,324 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:09,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:09,012 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:38:13,325 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:15,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:16,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:17,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:18,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:18,325 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:19,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:20,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:21,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:22,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:23,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:23,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:24,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:24,021 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:38:28,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:30,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:31,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:32,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:33,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:33,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:34,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:35,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:36,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:37,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:38,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:38,327 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:39,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:39,030 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:38:43,328 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:45,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:46,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:47,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:48,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:48,328 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:49,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:50,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:51,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:52,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:53,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:53,329 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:38:54,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:38:54,039 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:38:58,329 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:00,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:01,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:02,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:03,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:03,330 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:04,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:05,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:06,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:07,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:08,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:08,330 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:09,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:09,048 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:39:13,331 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:15,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:16,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:17,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:18,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:18,331 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:19,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:20,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:21,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:22,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:23,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:23,332 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:24,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:24,057 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:39:28,332 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:30,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:31,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:32,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:33,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:33,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:34,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:35,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:36,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:37,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:38,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:38,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:39,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:39,066 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:39:43,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:45,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:46,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:47,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:48,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:48,334 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:49,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:50,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:51,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:52,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:53,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:53,334 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:39:54,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:39:54,075 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:39:58,335 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:00,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:01,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:02,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:03,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:03,335 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:04,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:05,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:06,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:07,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:08,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:08,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:09,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:09,084 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:40:13,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:15,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:16,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:17,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:18,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:18,337 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:19,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:20,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:21,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:22,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:23,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:23,337 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:24,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:24,097 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:40:28,338 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:30,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:31,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:32,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:33,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:33,338 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:34,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:35,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:36,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:37,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:38,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:38,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:39,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:39,106 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:40:43,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:45,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:46,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:47,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:48,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:48,340 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:49,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:50,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:51,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:52,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:53,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:53,340 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:40:54,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:40:54,114 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:40:58,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:00,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:01,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:02,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:03,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:03,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:04,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:05,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:06,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:07,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:08,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:08,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:09,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:09,122 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:41:13,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:15,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:16,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:17,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:18,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:18,343 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:19,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:20,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:21,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:22,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:23,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:23,343 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:24,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:24,131 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:41:28,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:30,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:31,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:32,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:33,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:33,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:34,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:35,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:36,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:37,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:38,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:38,345 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:39,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:39,140 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:41:43,345 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:45,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:46,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:47,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:48,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:48,346 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:49,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:50,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:51,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:52,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:53,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:53,346 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:41:54,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:41:54,149 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:41:58,347 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:00,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:01,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:02,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:03,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:03,347 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:04,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:05,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:06,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:07,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:08,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:08,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:09,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:09,157 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:42:13,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:15,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:16,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:17,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:18,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:18,349 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:19,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:20,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:21,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:22,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:23,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:23,349 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:24,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:24,166 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:42:28,350 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:30,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:31,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:32,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:33,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:33,350 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:34,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:35,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:36,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:37,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:38,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:38,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:39,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:39,175 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:42:43,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:45,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:46,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:47,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:48,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:48,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:49,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:50,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:51,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:52,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:53,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:53,352 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:42:54,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:42:54,184 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:42:58,352 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:00,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:01,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:02,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:03,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:03,353 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:04,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:05,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:06,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:07,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:08,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:08,353 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:09,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:09,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:43:13,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:15,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:16,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:17,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:18,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:18,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:19,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:20,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:21,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:22,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:23,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:23,355 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:24,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:24,203 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:43:28,355 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:30,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:31,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:32,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:33,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:33,356 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:34,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:35,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:36,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:37,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:38,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:38,356 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:39,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:39,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:43:43,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:45,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:46,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:47,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:48,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:48,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:49,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:50,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:51,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:52,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:53,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:53,358 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:43:54,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:43:54,221 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:43:58,358 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:00,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:01,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:02,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:03,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:03,358 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:04,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:05,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:06,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:07,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:08,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:08,359 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:09,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:09,229 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:44:13,359 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:15,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:16,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:17,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:18,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:18,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:19,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:20,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:21,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:22,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:23,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:23,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:24,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:24,238 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:44:28,361 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:30,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:31,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:32,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:33,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:33,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:34,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:35,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:36,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:37,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:38,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:38,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:39,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:39,247 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:44:43,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:45,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:46,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:47,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:48,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:48,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:49,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:50,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:51,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:52,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:53,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:53,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:44:54,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:44:54,256 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:44:58,364 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:00,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:01,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:02,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:03,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:03,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:04,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:05,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:06,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:07,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:08,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:08,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:09,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:09,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:45:13,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:15,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:16,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:17,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:18,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:18,366 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:19,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:20,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:21,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:22,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:23,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:23,366 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:24,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:24,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:45:28,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:30,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:31,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:32,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:33,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:33,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:34,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:35,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:36,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:37,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:38,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:38,368 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:39,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:39,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:45:43,368 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:45,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:46,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:47,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:48,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:48,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:49,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:50,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:51,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:52,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:53,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:53,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:45:54,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:45:54,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:45:58,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:00,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:01,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:02,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:03,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:03,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:04,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:05,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:06,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:07,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:08,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:08,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:09,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:09,299 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:46:13,371 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:15,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:16,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:17,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:18,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:18,371 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:19,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:20,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:21,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:22,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:23,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:23,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:24,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:24,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:46:28,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:30,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:31,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:32,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:33,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:33,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:34,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:35,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:36,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:37,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:38,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:38,373 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:39,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:39,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:46:43,373 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:45,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:46,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:47,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:48,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:48,374 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:49,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:50,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:51,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:52,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:53,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:53,374 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:46:54,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:46:54,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:46:58,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:00,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:01,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:02,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:03,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:03,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:04,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:05,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:06,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:07,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:08,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:08,376 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:09,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:09,332 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:47:13,376 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:15,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:16,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:17,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:18,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:18,377 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:19,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:20,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:21,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:22,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:23,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:23,377 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:24,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:24,340 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:47:28,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:30,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:31,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:32,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:33,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:33,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:34,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:35,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:36,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:37,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:38,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:38,379 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:39,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:39,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:47:43,379 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:45,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:46,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:47,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:48,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:48,380 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:49,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:50,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:51,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:52,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:53,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:53,380 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:47:54,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:47:54,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:47:58,381 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:00,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:01,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:02,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:03,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:03,381 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:04,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:05,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:06,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:07,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:08,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:08,381 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:09,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:09,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:48:13,382 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:15,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:16,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:17,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:18,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:18,382 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:19,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:20,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:21,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:22,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:23,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:23,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:24,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:24,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:48:28,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:30,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:31,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:32,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:33,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:33,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:34,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:35,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:36,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:37,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:38,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:38,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:39,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:39,381 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:48:43,385 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:45,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:46,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:47,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:48,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:48,385 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:49,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:50,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:51,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:52,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:53,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:48:53,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:54,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:48:54,388 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:48:58,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:00,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:01,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:02,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:03,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:03,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:04,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:05,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:06,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:07,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:08,387 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:08,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:09,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:09,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:49:13,388 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:15,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:16,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:17,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:18,388 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:18,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:19,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:20,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:21,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:22,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:23,389 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:23,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:24,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:24,405 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:49:28,389 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:30,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:31,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:32,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:33,390 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:33,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:34,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:35,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:36,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:37,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:38,390 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:38,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:39,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:39,414 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:49:43,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:45,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:46,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:47,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:48,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:48,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:49,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:50,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:51,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:52,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:53,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:49:53,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:54,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:49:54,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:49:58,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:00,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:01,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:02,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:03,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:03,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:04,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:05,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:06,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:07,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:08,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:08,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:09,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:09,430 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:50:13,394 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:15,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:16,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:17,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:18,394 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:18,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:19,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:20,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:21,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:22,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:23,395 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:23,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:24,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:24,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:50:28,395 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:30,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:31,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:32,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:33,396 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:33,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:34,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:35,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:36,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:37,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:38,396 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:38,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:39,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:39,447 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop1/172.19.0.2:9000
2020-04-01 07:50:43,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:45,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:46,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:47,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:48,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:48,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:49,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:50,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:51,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:52,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-01 07:50:53,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoop2:9000
2020-04-01 07:50:53,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop1/172.19.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
